{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SARS-ARENA: Structure-based identification of SARS-derived peptides with potential to induce broad protective immunity\n",
    "\n",
    "## *Workflow 1A* - Sequence Alignment and Peptide Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the Sequence Alignment and Peptide Selection **Workflow 1A**. This notebook will allow you to search and download SARS-CoV-2 proteins from NCBI in a specified date of deposition. At the end, you will be able to align these protein sequences and search for conserved regions according to your especifications. The peptide's list output can be used in the subsequent workflow. (**Workflow 2: Peptide-HLA Prediction for Conserved SARS-CoV-2 Peptides**) \n",
    "\n",
    "This workflow consists of five steps: \n",
    "    1. Fetch dataset from NCBI,\n",
    "    2. Extract and filter the sequence file,\n",
    "    3. Multiple Sequence Alignment, \n",
    "    4. Computing conservation score, and \n",
    "    5. Computing conserved peptides.\n",
    "    \n",
    "In case you need to align **more than 2000 proteins**, we recommend you to use the [Workflow 1B](http://127.0.0.1:8888/notebooks/ProjectDevelopment/Peptide_Extraction_Workflow_1B.ipynb).\n",
    "\n",
    "**In order to run a cell, first click on the cell, then press shift-enter. The code inside the cell will then be executed. Note that the content of the cell can be executed as Code or Markdown. Also, inside the cell you may find comments to explain a specific command. These comments are marked with \"#\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1) Fetch dataset from NCBI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first part, you will be able to download the SARS-CoV-2 protein dataset directly from NCBI, using the python package for calling the NCBI datasets API. You can find more information [here](https://github.com/ncbi/datasets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Necessary imports:\n",
    "Run this cell to make the necessary imports. This cell should be run only one time, unless you close this session and open it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System-based imports\n",
    "import os\n",
    "\n",
    "# Subprocess module\n",
    "from subprocess import PIPE, run\n",
    "import multiprocessing\n",
    "\n",
    "# Data processing\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(18, 8)}) # Use seaborn style defaults and set the default figure size\n",
    "\n",
    "# For utility functions used within the code\n",
    "from SARS_Arena import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Setting a working directory:\n",
    "Choose an appropriate directory for storing all the files or use the default (*Peptide_Extraction_Workflow*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_of_workflow_1 = \"./Peptide_Extraction_Workflow_1A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(dir_of_workflow_1, exist_ok=True)\n",
    "os.chdir(dir_of_workflow_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Arguments for the API:\n",
    "The protein sequences will be retrieved from online databases. Change these arguments according to your preference. These are the options available (*default values are shown*):\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "    proteins = 'N'\n",
    "This workflow is focused on N protein. However, you can choose a protein to be analyzed from the following list: ORF1ab, ORF1a, nsp1, nsp2, nsp3, nsp4, nsp5, nsp6, nsp7, nsp8, nsp9, nsp10, nsp11, nsp13, nsp14, nsp15, nsp16, RdRp, S, ORF3a, E, M, ORF6, ORF7a, ORF7B, ORF8, N, ORF10\n",
    "    \n",
    "    refseq_only = False\n",
    "Choose between 'True' (use reference sequences only) or 'False' (use all sequences available)\n",
    "    \n",
    "    annotated_only = True\n",
    "Choose between 'True' (only assemblies with annotation) or 'False' (include assemblies without annotation)\n",
    "\n",
    "    complete_only = True\n",
    "Choose between 'True' (only include complete genomes) or 'False' (include incomplete genomes)\n",
    "\n",
    "    host = \"human\"\n",
    "Choose the host. Currently, we have only the \"human\" (Homo sapiens) option available.\n",
    "\n",
    "    release_since = \"2021-01-01T00:00:00+00:00\"\n",
    "Choose the sequences to be retrieved base on the release date. Format \"Date(Year-Month-Day), Time(Hour-Minute-Seconds) and Timezone\". Example - April 1, 2020 midnight UTC should be formatted as follows: 2020-04-01T00:00:00.000Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proteins = 'N'          # list[str]\n",
    "refseq_only = False     # bool\n",
    "annotated_only = True   # bool\n",
    "complete_only = True    # bool\n",
    "host = \"human\"          # str\n",
    "\n",
    "released_since = '2021-12-03T00:00:00+00:00' # datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2) Extract and filter the sequence file:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have defined which proteins should be analyzed, it is time to extract and filter this proteins according to your preferences. In this section, python code automatically extracts the .faa dataset that contains the protein sequences, and there is additional filtering to keep cleaner sequences (or a subset of those)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Extract the .faa sequence file from */tmp/ncbi_dataset.zip*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_file = call_ncbi_datasets(proteins, refseq_only, annotated_only, complete_only, host, released_since)\n",
    "print(sequence_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Check the total number of protein sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_sequences = count_sequences(sequence_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Choose the number of sequences to work with\n",
    "\n",
    "In this step you can choose how many sequences should be used in Step 3 (Multiple Sequence Alignment). The default is to use all sequences after filtering, but you can choose a different number. For instance, if you choose `no_of_sequences` = 1000, the first 1000 sequences from *protein.faa* file will be used (the oldest ones are on the top of the file). **If you decide to use all sequences, make sure you inserted a \"#\" in front of 'no_of_sequences'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sequence_file = \"protein_first_N.faa\"\n",
    "no_of_sequences = 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the function to filter out sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sequence_file) as s_file:\n",
    "    print(read_faa(s_file, filtered_sequence_file, no_of_sequences))\n",
    "s_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3) Multiple Sequence Alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step you will perform the Multiple Sequence Alignment based on the sequences you have chosen. This is performed with the software [MAFFT](https://mafft.cbrc.jp/alignment/software/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Run in parallel (optional)\n",
    "In case your machine has multiple cores, you can select a specific number of cores to run the alignment. If your machine has a single core, you can move to step 3.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below in case you don't know how many cores your machine has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of cores :\", multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, define the number of cores to be used (`ncores`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncores = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Run the Multiple Sequence Alignment \n",
    "After run this cell, you will be able to see a consensus sequence for this alignment. Choose a threshold for calculating the consensus sequence (frequencies below this threshold will have an unknown amino acid)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "consensus_sequence = run_msa(filtered_sequence_file, ncores, threshold)\n",
    "print(consensus_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alignment Scoring**: After the *MAFFT* algorithm performs the alignment, the **aligned.fasta** file will contain all the aligned sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4) Computing conservation score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the file with the aligned sequences, you can now score each position in terms of conservation. We offer four scoring method options:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *Jensen-Shannon divergence score* (used as 'js_divergence') (**Recommended**)\n",
    "- *Shannon Entropy* (used as 'shannon_entropy')\n",
    "- *Property entropy* (used as 'property_entropy')\n",
    "- *Von Neumann entropy* (used as 'vn_entropy')\n",
    "\n",
    "For details on the scoring method options, please consult [Capra & Singh (2007)](https://academic.oup.com/bioinformatics/article/23/15/1875/203579)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For scoring matrices you can choose one of the BLOSUM options:\n",
    "- BLOSUM62 (**Recommended**)\n",
    "- BLOSUM35\n",
    "- BLOSUM40\n",
    "- BLOSUM45\n",
    "- BLOSUM50\n",
    "- BLOSUM80\n",
    "- BLOSUM100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_method = 'js_divergence'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_matrix = 'blosum62' #This only applies to methods that actually use a scoring matrix for calculating conservation, like JS-divergence, else, it is ignored (e.g. Shannon Entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the arguments have been defined, run the conservation analysis and store the conservation results in the `conservation_file` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conservation_file = conservation_analysis(scoring_method, scoring_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5) Computing conserved peptides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the final step of this workflow you will be able to compute the conservation of peptides based on residue conservation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Retrieve information on conservation residues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conservation_df = pd.read_csv(filepath_or_buffer = conservation_file,\n",
    "                              header = 0,\n",
    "                              names = ['Position', 'Score', 'Alignment'],\n",
    "                              converters={'Score': lambda x: max(float(x)*100, 0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conservation_df #Show the conservation by residue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now fetch the aligned sequences, where we extract the peptides from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_sequences_df = pd.read_csv(filepath_or_buffer = \"aligned.csv\",\n",
    "                                   header = 0,\n",
    "                                   names = ['Sequence_ID', 'Aligned_Sequences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_sequences_df #Show the aligned sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, before using the interactive plot to filter the peptides by conservation, we will pre-compute all the peptides in the sequences. For that, define the peptide length boundaries you want to analyze and extract the peptides:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 10 #Maximum length of the peptide\n",
    "min_len = 8 #Minimum length of the peptide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_peptides_from_sequences = extract_peptides(min_len, max_len, aligned_sequences_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_peptides_from_sequences # (optional) Run this cell if you want to see the extracted peptides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Choose the peptides based on conservation values:\n",
    "Use the sliders below the cell (after run) to set the following parameters:\n",
    "\n",
    "- *Conservation threshold (CV_cutoff)*: Conservation degree of the peptides.\n",
    "- *Rolling Median Window length (RMW_cutoff)*: As conservation values are different and not homogeneous for each position, the regions can be smoothed based on this filter. Alternatively, you can set to 1 to take conservation as it is. \n",
    "- *Peptide Length (Pep_length)*: Fetch peptides of desired length for post-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_plot_selection(conservation_df, extracted_peptides_from_sequences, min_len, max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Print the peptides:\n",
    "\n",
    "Print the peptides sequence based on the threshold set above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptide_file = open(\"peptides.list\", \"r\")\n",
    "peptide_list = peptide_file.readlines()\n",
    "peptide_list = [peptide.strip() for peptide in peptide_list] \n",
    "print(peptide_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+2\"><center><b>This is the end of Workflow 1A</font></center></b>\n",
    "\n",
    "\n",
    "You will find a file named *peptides.list* in your folder that can be used as input for the [Workflow 2](Peptide-HLA_Binding_Prediction_Workflow_2.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
