{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SARS-ARENA: Structure-based identification of SARS-derived peptides with potential to induce broad protective immunity\n",
    "\n",
    "## *Workflow 1A* - Sequence Alignment and Peptide Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the Sequence Alignment and Peptide Selection **Workflow 1A**. This notebook will allow you to search and download SARS-CoV-2 proteins from NCBI in a specified date of deposition. At the end, you will be able to align these protein sequences and search for conserved regions according to your especifications. The peptide's list output can be used in the subsequent workflow. (**Workflow 2: Peptide-HLA Prediction for Conserved SARS-CoV-2 Peptides**) \n",
    "\n",
    "This workflow consists of five steps: \n",
    "    1. Fetch dataset from NCBI Virus,\n",
    "    2. Extract and filter the sequence file,\n",
    "    3. Multiple Sequence Alignment, \n",
    "    4. Computing conservation score, and \n",
    "    5. Computing conserved peptides.\n",
    "    \n",
    "In case you need to align **more than 50,000 proteins**, we recommend you to use the [Workflow 1B](http://127.0.0.1:8888/notebooks/Peptide_Extraction_Workflow_1B.ipynb).\n",
    "\n",
    "**In order to run a cell, first click on the cell, then press shift-enter. The code inside the cell will then be executed. Note that the content of the cell can be executed as Code or Markdown. Also, inside the cell you may find comments to explain a specific command. These comments are marked with \"#\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1) Fetch dataset from NCBI Virus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first part, you will be able to download the SARS-CoV-2 protein dataset directly from NCBI Virus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mauricio: This is necessary given the docker image that we have. We an say to Anja that \n",
    "# uploaded the last version of the image that included 3pHLA to also add curl, we need it to download the sequences\n",
    "!apt-get update -y\n",
    "!apt-get install curl -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Necessary imports:\n",
    "Run this cell to make the necessary imports. This cell should be run only one time, unless you close this session and open it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System-based imports\n",
    "import os\n",
    "\n",
    "# Subprocess module\n",
    "from subprocess import PIPE, run\n",
    "import multiprocessing\n",
    "\n",
    "# Data processing\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(18, 8)}) # Use seaborn style defaults and set the default figure size\n",
    "\n",
    "# For utility functions used within the code\n",
    "from SARS_Arena import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Setting a working directory:\n",
    "Choose an appropriate directory for storing all the files or use the default (*Peptide_Extraction_Workflow*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_of_workflow_1 = \"Peptide_Extraction_Workflow_1A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(dir_of_workflow_1, exist_ok=True)\n",
    "os.chdir(dir_of_workflow_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Arguments for the API:\n",
    "The protein sequences will be retrieved from online databases. For each tab, change the arguments according to your preferences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tab = create_tab(os.getcwd())\n",
    "dataset_selection(tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate the selection you made above before proceeding.\n",
    "\n",
    "**WARNING**: Do not skip running this cell after you specified you arguments above, as in needs to be run to update the values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Virus_Type, Protein, Completeness, Host, Refseq, Geographic_region, Isolation_source, Pangolin_lineage, Released_Dates = extract_elements(tab)\n",
    "\n",
    "print(\"The following is the selection made using the UI above. Return to it to make corrections if needed!\")\n",
    "print('-------')\n",
    "\n",
    "# Virus\n",
    "print(\"Virus type: \" + Virus_Type)\n",
    "\n",
    "# Protein\n",
    "print(\"Protein type: \" + Protein)\n",
    "\n",
    "# Protein\n",
    "print(\"Sequence type: \" + Refseq)\n",
    "\n",
    "# Completeness\n",
    "print(\"Completeness type: \" + Completeness)\n",
    "\n",
    "# Host\n",
    "print(\"Host type: \" + Host)\n",
    "\n",
    "# Geography\n",
    "print(\"Geographic type: \" + Geographic_region[0])\n",
    "print(\"Geographic selection: \" + str(Geographic_region[1]))\n",
    "\n",
    "# Isolation source|\n",
    "print(\"Isolation source: \" + str(Isolation_source))\n",
    "\n",
    "# Pangolin source\n",
    "print(\"Pangolin lineage: \" + str(Pangolin_lineage))\n",
    "\n",
    "# Dates\n",
    "print(\"From \" + str(Released_Dates[0]) + \" to \" + str(Released_Dates[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2) Extract and filter the sequence file:\n",
    "\n",
    "Now that you have defined which sequences should be analyzed, it is time to extract these sequences. In this section, python code automatically extracts the .fasta file that contains the protein sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Download the .fasta sequence file from NCBI Virus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_file = call_ncbi_virus(Virus_Type, Protein, Completeness, Host, Refseq, Geographic_region, \n",
    "                                     Isolation_source, Pangolin_lineage, Released_Dates)\n",
    "print(sequence_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Check the total number of protein sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_sequences = count_sequences(sequence_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3) Multiple Sequence Alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step you will perform the Multiple Sequence Alignment based on the sequences you have chosen. This is performed with the software [MAFFT](https://mafft.cbrc.jp/alignment/software/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Run in parallel (optional)\n",
    "In case your machine has multiple cores, you can select a specific number of cores to run the alignment. If your machine has a single core, you can move to step 3.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below in case you don't know how many cores your machine has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of cores :\", multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, define the number of cores to be used (`ncores`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncores = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Run the Multiple Sequence Alignment \n",
    "After running this cell, you will be able to see a consensus sequence for this alignment. Choose a threshold for calculating the consensus sequence (frequencies below this threshold will have an unknown amino acid)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING:** Be aware that the more sequences you have in total, the more waiting time there is for MAFFT to finish. As suggested in the start of the workflow, if you want to do just the conservation analysis on sequences that are already aligned, use Workflows 1B and 1C instead!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "consensus_sequence = run_msa(sequence_file, ncores, threshold)\n",
    "print(consensus_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alignment Scoring**: After the *MAFFT* algorithm performs the alignment, the **aligned.faa** file will contain all the aligned sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4) Computing conservation score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the file with the aligned sequences, you can now score each position in terms of conservation. We offer four scoring method options:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *Jensen-Shannon divergence score* (used as 'js_divergence') (**Recommended**)\n",
    "- *Shannon Entropy* (used as 'shannon_entropy')\n",
    "- *Property entropy* (used as 'property_entropy')\n",
    "- *Von Neumann entropy* (used as 'vn_entropy')\n",
    "\n",
    "For details on the scoring method options, please consult [Capra & Singh (2007)](https://academic.oup.com/bioinformatics/article/23/15/1875/203579)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For scoring matrices you can choose one of the BLOSUM options:\n",
    "- BLOSUM62 (**Recommended**)\n",
    "- BLOSUM35\n",
    "- BLOSUM40\n",
    "- BLOSUM45\n",
    "- BLOSUM50\n",
    "- BLOSUM80\n",
    "- BLOSUM100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_method = 'js_divergence'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_matrix = 'blosum62' #This only applies to methods that actually use a scoring matrix for calculating conservation, like JS-divergence, else, it is ignored (e.g. Shannon Entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the arguments have been defined, run the conservation analysis and store the conservation results in the `conservation_file` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conservation_file = conservation_analysis(scoring_method, scoring_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5) Computing conserved peptides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the final step of this workflow you will be able to compute the conservation of peptides based on residue conservation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Retrieve information on conservation residues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conservation_df = pd.read_csv(filepath_or_buffer = conservation_file,\n",
    "                              header = 0,\n",
    "                              names = ['Position', 'Score', 'Alignment'],\n",
    "                              converters={'Score': lambda x: max(float(x)*100, 0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conservation_df #Show the conservation by residue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now fetch the aligned sequences, where we extract the peptides from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_sequences_df = pd.read_csv(filepath_or_buffer = \"aligned.csv\",\n",
    "                                   header = 0,\n",
    "                                   names = ['Sequence_ID', 'Aligned_Sequences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_sequences_df #Show the aligned sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, before using the interactive plot to filter the peptides by conservation, we will pre-compute all the peptides in the sequences. For that, define the peptide length boundaries you want to analyze and extract the peptides:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 10 #Maximum length of the peptide\n",
    "min_len = 8 #Minimum length of the peptide\n",
    "extracted_peptides_from_sequences = extract_peptides(min_len, max_len, aligned_sequences_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Choose the peptides based on conservation values:\n",
    "Use the sliders below the cell (after run) to set the following parameters:\n",
    "\n",
    "- *Conservation threshold (CV_cutoff)*: Conservation degree of the peptides.\n",
    "- *Rolling Median Window length (RMW_cutoff)*: As conservation values are different and not homogeneous for each position, the regions can be smoothed based on this filter. Alternatively, you can set to 1 to take conservation as it is. \n",
    "- *Peptide Length (Pep_length)*: Fetch peptides of desired length for post-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_plot_selection(conservation_df, extracted_peptides_from_sequences, min_len, max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Print the peptides:\n",
    "\n",
    "Print the peptides sequence based on the threshold set above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptide_file = open(\"peptides.list\", \"r\")\n",
    "peptide_list = peptide_file.readlines()\n",
    "peptide_list = [peptide.strip() for peptide in peptide_list] \n",
    "print(peptide_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+2\"><center><b>This is the end of Workflow 1A</font></center></b>\n",
    "\n",
    "\n",
    "You will find a file named *peptides.list* in your folder that can be used as input for the [Workflow 2](Peptide-HLA_Binding_Prediction_Workflow_2.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
